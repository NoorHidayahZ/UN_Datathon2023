{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e55a9941-3221-4687-8f02-784234d229a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/sparkuser/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.8/site-packages (1.28.78)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.78 in /opt/conda/lib/python3.8/site-packages (from boto3) (1.31.78)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from boto3) (0.7.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.8/site-packages (from botocore<1.32.0,>=1.31.78->boto3) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.8/site-packages (from botocore<1.32.0,>=1.31.78->boto3) (1.26.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.78->boto3) (1.15.0)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/sparkuser/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.8/site-packages (4.9.3)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3\n",
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "688f68ad-b5d2-467b-894e-d2acd1c3c002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File tmp3_2ohsg8 uploaded to datathon-user-bucket-datatricks1.\n"
     ]
    }
   ],
   "source": [
    "# be sure to run !pip install boto3 in your notebook\n",
    " \n",
    "import os\n",
    "import tempfile\n",
    "import boto3\n",
    "\n",
    "# AWS_ACCESS_KEY_ID=\"ASIA3KAKBKFJKIY3RR5Y\"\n",
    "# AWS_SECRET_ACCESS_KEY=\"7ukATEPPTA7z5tv227DltV2abaB9mbdw2DrAu4Z3\"\n",
    "# AWS_SESSION_TOKEN=\"IQoJb3JpZ2luX2VjEDwaCXVzLWVhc3QtMSJHMEUCIAEczbbS4Nq5XLEG9YiiNegC8l00xzUvdT1M9kirdZcdAiEAtNulJ4daAx8WyScnaZpcTHjcDgpRnHf7I/ORq8PvXsYqmQIIdRAAGgw3Nzc0MTAxMzg0NTAiDFu0Id5Nn1LxlLuEoSr2AYI09mvVmJ54WYyfhhtpE3nB938CWSQVvr2XeTxQ+ENmTOxi5J7UE7aBsWXkjFxlQ8k86h4kRE1p2JpkKNr4uOExkoSbcfZTq6gNKxOazldm8VNWc1elsT812A5+IJUuNt5A0xfAQwGabJ3PSDgCdD3+I5UvPTgx+j6pSn+3yW7Aepce+iOHmpHY9ry3Csg9p0rsV30OfejEXDTtcD0QzP4K8iSozC9FOy04/CDePDranVQBjttkX/n3xdX8nQsbGJ8IhYBtC6SGd1OnRgKO6NVC1T427hvjO4VO6xHH+x+hubG3Tc8upofdPB5fy2E5bHS6oT0kSjCi+J2qBjqdAT8EfLYVAhajXS/Ab7SioPvrwLQP2ig524BakU71xAEmUDEPDI8oz8S6uSfoyscuXpjwlDsL0pUHRTDoXCyKXVEq2k9w8NtVpJcepmz5Td/70ltI9CFt5IBLyHVkDoAxKUVM+vF7JbCG+wXij1uZjpv0wsQuQCUSV7wMbvanoV6I8nVDS0CqNCC4YC9qE6BE5xwD/AIwk3Kah1yBrwk=\"\n",
    "#AWS_ACCESS_KEY_ID=\"ASIA3KAKBKFJNSH2GEWG\"\n",
    "#AWS_SECRET_ACCESS_KEY=\"WxFiEe9AzxJeSvqB4OHr+vjsUzsvVgJd3+ekhsQQ\"\n",
    "#AWS_SESSION_TOKEN=\"IQoJb3JpZ2luX2VjED0aCXVzLWVhc3QtMSJHMEUCIDoAaVM1vKVdp6cVnnm1sqPp3bPLfYi6vIbVXrwk6PPGAiEAoDrVUMt8Jp6MOVeYvRDXh5nHpgJpt7HBgR4vBZCsmQ4qmQIIdhAAGgw3Nzc0MTAxMzg0NTAiDFyKoKe/P7MLcqTGUir2AQDJez8zWtL1Z7FWq0Wpyp8Jug9riE452UBez6hc1G5nCqh2o7ZpyjCmV2lpRfCGOGETsYwwPMpbMr+QsTqcgDBHh5GX5CoJz95HnnHjTEC8aigs8L2xHjQqPr4GhLWEQ31mMfAzISjpCnzvFCx3xir1+CnW8vt6PnUXkDXAWLlxDfgj5SBKAMn+GdrjR/EsNNUE6cFfsZ4V0J/G+abSvi9b/mznHPedbAzSXPIVVcrMaN/L4wzfGUj5ldBfZa2baapVFv6ZnJyX2jJxp0LRq4jjmKCmFBWZ1Va2d6SCaJh70o0lquTRskUk6QpaWPWnN3Ncwt8WsjD/nJ6qBjqdAQtCq8GXqGTgxSBzt7C2ZT0kYWLNZqDEa6XyT6QYH28WUWzlrJlBIxK7qyaAKJ8hVPpbNo1qhcPPmVxXbbwycginl9wnxqLsSL9rrKC8uI7FXFMUgl/SQLaI3GMK0PbKgOXQ6Uw4wxIX5Qg/GkUULBQcWJEOGPP7qvlXlUD7fhjYMjbugupRl0PH6ce9KIGgn1euPqt1HouU1NJ9YTg=\"\n",
    "AWS_ACCESS_KEY_ID=\"ASIA3KAKBKFJEE6AGEOS\"\n",
    "AWS_SECRET_ACCESS_KEY=\"qUXRcFeQwxZ5IQDYcfMAOSJW3t/jJI/nj91yaYA3\"\n",
    "AWS_SESSION_TOKEN=\"IQoJb3JpZ2luX2VjEEgaCXVzLWVhc3QtMSJHMEUCIAZZGMxg90c4Zqr6gnXTH7TqI9YyUK4JDC0/OlWJrKUjAiEA6AtU+YsqAfdVdFU/sNSSlUrePgi5Tfbc/8PRac8/slEqogIIgf//////////ARAAGgw3Nzc0MTAxMzg0NTAiDImRrOvyq+bES3rOpSr2AQFF/kHbEx9dV6J6HtkjR9W+Z9bqpSvQUSkjHhekqtD7fz1xMvyBStRdKFSGSNRpKTUu04/qG4ljtRiE3k/PNAwE7eFGBkQrfJPP90ZbOy6i7WDue3axKHkPlLyb9wkGcm0SB0iJOz45w0zEkc8YrMa2bnI294OoHXzdggnIz6qLpnfYmQCC1wRexYqSOls1yrCdYTbV8uJc3FCTq4x1WAsrd+G+mR0jCh+zkRfSH2MVDjqxQd91rMECPbCC993KcfbbTaKTZJd5kK3RDeLS0HQYMt1p2O94NPQaYtCHOZjPnzs7IXUAk7ljc9etJ/aiF3ARNPXzRTD22qCqBjqdAbcIDL+ibVBGUMF7ZdetFNE8bogA1dcSAVwt24ncHelJngXrd5gP6XqMJroOUqU3c2LY5Ks0fExgWbMYGHri5Mg+VZqsbvtVA+XdiwaRa10R8QTpbH4/nwhojqaT1z1PbSidD3IXgwPYEt9i5PJbAzs5QkFKSIIIc24ww3GqJ6Le7NMyAew5D38LNF9JTtfOd77Q6IraHkflgO46uxo=\"\n",
    "\n",
    "# session = boto3.Session(\n",
    "#     aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "#     aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "#     aws_session_token=AWS_SESSION_TOKEN\n",
    "# )\n",
    "\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    aws_session_token=AWS_SESSION_TOKEN\n",
    ")\n",
    "\n",
    "BUCKET_NAME = 'datathon-user-bucket-datatricks1'\n",
    " \n",
    "def create_fake_file():\n",
    "    with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n",
    "        temp_file.write(b'This is some fake data for testing.')\n",
    "        return temp_file.name\n",
    "\n",
    "def upload_file_to_s3(file_path, bucket_name):\n",
    "    # s3 = boto3.client('s3')\n",
    "    file_name = os.path.basename(file_path)\n",
    "    try:\n",
    "        s3.upload_file(file_path, bucket_name, file_name)\n",
    "        print(f\"File {file_name} uploaded to {bucket_name}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading file {file_name} to {bucket_name}: {e}\")\n",
    "\n",
    "def main():\n",
    "    fake_file_path = create_fake_file()\n",
    "    upload_file_to_s3(fake_file_path, BUCKET_NAME)\n",
    "    os.remove(fake_file_path)\n",
    "\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b76f0fe-1e78-43b4-b2cc-cec5693aafbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# necessary import functions\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from sedona.register import SedonaRegistrator\n",
    "SedonaRegistrator.registerAll(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01baf8a2-993a-4d78-bec2-fd6e47cf724e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "# save a local CSV from the notebook\n",
    "def create_download_link(df, title=\"Download CSV file\", filename=\"data.csv\"):\n",
    "    csv = df.to_csv()\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload, title=title, filename=filename)\n",
    "    return HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca7c61fb-2fde-4eac-b18c-53e4f35245ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read in UNGP S3 data from a range of dates\n",
    "def get_date_list(basepath, start_date, end_date):\n",
    "    start_date = datetime.datetime.strptime(start_date, \"%Y-%m-%d\").date()\n",
    "    end_date = datetime.datetime.strptime(end_date, \"%Y-%m-%d\").date()\n",
    "    delta = end_date - start_date\n",
    "    days = []\n",
    "    for i in range(delta.days + 1):\n",
    "        day = start_date + datetime.timedelta(days=i)\n",
    "        days.append(datetime.datetime.strftime(day, \"%Y-%m-%d\"))\n",
    "    \n",
    "    paths = [basepath + f\"year={day[:4]}/month={day[5:7]}/day={day[8:10]}\" for day in days]\n",
    "    return (paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8c8963f-c0ed-44f4-9e3c-84c5fd9f81b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Port Klang',\n",
       " 3.0069444444444446,\n",
       " 101.35583333333332,\n",
       " 'Tanjung Pelepas Port',\n",
       " 1.353611111111111,\n",
       " 103.54416666666667)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pklang = \"http://www.worldportsource.com/ports/MYS_Port_Klang_273.php\"\n",
    "ptpelepas = \"http://www.worldportsource.com/ports/MYS_Tanjung_Pelepas_Port_1442.php\"\n",
    "klang = pd.read_html(pklang)[0]\n",
    "ptp = pd.read_html(ptpelepas)[0]\n",
    "def cleanup(df):\n",
    "    df[0] = df[0].str.replace(\":\", \"\")\n",
    "    df.set_index(0, inplace=True)\n",
    "    df.drop(df.columns[0], axis=1, inplace=True)\n",
    "    df.dropna(how='all',axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "klang = cleanup(klang)\n",
    "ptp = cleanup(ptp)\n",
    "\n",
    "def dms_to_dd(degrees, minutes, seconds, direction):\n",
    "    dd = float(degrees) + float(minutes)/60 + float(seconds)/(60*60)\n",
    "    if direction in ['S', 'W']:\n",
    "        dd *= -1\n",
    "    return dd\n",
    "\n",
    "def dms_to_decimal(dms_string):\n",
    "    # Use regular expressions to extract degrees, minutes, and seconds\n",
    "    match = re.search(r'(\\d+)° (\\d+)\\' (\\d+)\" ([NSEW])', dms_string)\n",
    "    if match:\n",
    "        degrees, minutes, seconds = map(int, match.groups()[:3])\n",
    "        direction = match.groups()[3]\n",
    "        decimal_degrees = dms_to_dd(degrees, minutes, seconds, direction)\n",
    "        return decimal_degrees\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# extract port klang latitude and longitude from table convert to float\n",
    "klang_lat = dms_to_decimal(klang.loc['Latitude'].values[0])\n",
    "klang_long = dms_to_decimal(klang.loc['Longitude'].values[0])\n",
    "ptp_lat = dms_to_decimal(ptp.loc['Latitude'].values[0])\n",
    "ptp_long = dms_to_decimal(ptp.loc['Longitude'].values[0])\n",
    "klang_name = klang.loc['Port Name'].values[0]\n",
    "ptp_name = ptp.loc['Port Name'].values[0]\n",
    "klang_name,klang_lat,klang_long,ptp_name,ptp_lat,ptp_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae6e6a44-ec06-41c0-85db-216410b6ac69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(start_date, end_date, location_name,longitude,latitude, distance_parameter = \"0.005\"):\n",
    "    # distance parameter = 0.01 = 1 kilometer radius\n",
    "    \n",
    "    # all geographies in one query\n",
    "    condition_string = \"\"\n",
    "    select_string = \"\"\n",
    "    condition_string += f\"\"\"ST_Contains(ST_Buffer(ST_Point({longitude}, {latitude}), {distance_parameter}), pos) \"\"\"\n",
    "    select_string += f\"\"\"CASE WHEN ST_Contains(ST_Buffer(ST_Point({longitude}, {latitude}), {distance_parameter}), pos) THEN '{location_name}' \"\"\"\n",
    "    select_string += \"END AS geo_name\"\n",
    "    \n",
    "    # step 1\n",
    "    # read data\n",
    "    basepath = \"s3a://ungp-ais-data-historical-backup/exact-earth-data/transformed/prod/\"\n",
    "    dates = get_date_list(basepath, start_date, end_date)\n",
    "    df = spark.read.parquet(*dates)\n",
    "\n",
    "    # create temp view to be able to use spark SQL\n",
    "    df.createOrReplaceTempView(\"df\")\n",
    "\n",
    "    # adding points and filtering for cargo and tankers\n",
    "    step_01 = spark.sql(f\"\"\"\n",
    "                    SELECT * FROM\n",
    "                    (\n",
    "                        SELECT \n",
    "                            dt_pos_utc, \n",
    "                            mmsi, \n",
    "                            vessel_type,\n",
    "                            longitude, \n",
    "                            latitude, \n",
    "                            ST_Point(cast(longitude as Decimal(24,20)), cast(latitude as Decimal(24,20))) as pos \n",
    "                        FROM df\n",
    "                        WHERE vessel_type IN ('Cargo','Tanker')\n",
    "                    ) AS subquery\n",
    "                    WHERE {condition_string}\n",
    "                    \"\"\")\n",
    "    step_01.createOrReplaceTempView(\"step_01\")\n",
    "    \n",
    "    # step 2\n",
    "    # filtering for ships that are within 1km of the point\n",
    "    step_02 = spark.sql(f\"\"\"\n",
    "                    SELECT\n",
    "                        geo_name,\n",
    "                        date,\n",
    "                        vessel_type,\n",
    "                        COUNT(DISTINCT mmsi) AS num_ships\n",
    "                    FROM \n",
    "                        (SELECT\n",
    "                            mmsi,\n",
    "                            {select_string},\n",
    "                            SUBSTRING(CAST(dt_pos_utc AS VARCHAR(10)), 1, 10) AS date,\n",
    "                            vessel_type\n",
    "                        FROM step_01\n",
    "                        ) AS subquery\n",
    "                    GROUP BY date, vessel_type, geo_name\n",
    "                    \"\"\")\n",
    "    \n",
    "    return (step_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81a4cfb7-0a73-48d4-a362-2526b1fafbf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2020-03-01': None,\n",
       " '2020-04-01': None,\n",
       " '2020-05-01': None,\n",
       " '2020-06-01': None,\n",
       " '2020-07-01': None,\n",
       " '2020-08-01': None,\n",
       " '2020-09-01': None,\n",
       " '2020-10-01': None,\n",
       " '2020-11-01': None,\n",
       " '2020-12-01': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# queries for months\n",
    "start_month = datetime.datetime.strptime(\"2020-03-01\", \"%Y-%m-%d\")\n",
    "end_month = datetime.datetime.strptime(\"2020-12-01\", \"%Y-%m-%d\")\n",
    "\n",
    "start_dates = []\n",
    "end_dates = []\n",
    "\n",
    "while start_month <= end_month:\n",
    "    start_dates.append(datetime.datetime.strftime(start_month, \"%Y-%m-%d\"))\n",
    "    end_date = min(start_month + relativedelta(months=1) - relativedelta(days = 1), datetime.datetime.today() - relativedelta(days=2)) # minimum between 2 days ago so don't go ahead of where there are actually files\n",
    "    end_dates.append(datetime.datetime.strftime(end_date, \"%Y-%m-%d\"))\n",
    "    start_month = start_month + relativedelta(months=1)\n",
    "\n",
    "date_dict = {x: None for x in start_dates}\n",
    "date_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a2b8404-60dd-46ce-8f46-c984ad31f6d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# start_d = \"2022-01-01\" #, \"%Y-%m-%d\")\n",
    "# end_d = \"2022-01-02\" #, \"%Y-%m-%d\")\n",
    "# start_d,end_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8ab342a-e5ba-4377-8c9a-99c9407e8032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_x = get_data(start_d, end_d, klang_name,klang_long,klang_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91eb033b-0731-4ff4-be67-9d6d3b1238ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dx = data_x.toPandas()\n",
    "# dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f05cac9-cfdc-4496-8a96-fc4927c31154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file_path = \"klang2020.csv\"\n",
    "# start_dates,end_dates\n",
    "# dx.to_csv(file_path)\n",
    "# upload_file_to_s3(file_path, BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb7b9eff-499a-47c3-93f5-9542216bcc34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File klang_2020-03-01.csv uploaded to datathon-user-bucket-datatricks1.\n",
      "File klang_2020-04-01.csv uploaded to datathon-user-bucket-datatricks1.\n",
      "File klang_2020-05-01.csv uploaded to datathon-user-bucket-datatricks1.\n",
      "File klang_2020-06-01.csv uploaded to datathon-user-bucket-datatricks1.\n",
      "File klang_2020-07-01.csv uploaded to datathon-user-bucket-datatricks1.\n",
      "File klang_2020-08-01.csv uploaded to datathon-user-bucket-datatricks1.\n",
      "File klang_2020-09-01.csv uploaded to datathon-user-bucket-datatricks1.\n",
      "File klang_2020-10-01.csv uploaded to datathon-user-bucket-datatricks1.\n",
      "File klang_2020-11-01.csv uploaded to datathon-user-bucket-datatricks1.\n",
      "File klang_2020-12-01.csv uploaded to datathon-user-bucket-datatricks1.\n"
     ]
    }
   ],
   "source": [
    "location_name = klang_name\n",
    "longitude = klang_long\n",
    "latitude = klang_lat\n",
    "\n",
    "for i in range(len(start_dates)):\n",
    "    date_dict[start_dates[i]] = get_data(start_dates[i], end_dates[i], location_name,longitude,latitude)\n",
    "    dx = date_dict[start_dates[i]].toPandas()\n",
    "    file_path=f\"klang_{start_dates[i]}.csv\"\n",
    "    dx.to_csv(file_path)\n",
    "    upload_file_to_s3(file_path, BUCKET_NAME)\n",
    "    create_download_link(dx, filename=file_path)\n",
    "    # os.remove(file_path)\n",
    "\n",
    "# html_return = create_download_link(date_dict[\"2022-01-01\"].toPandas(), filename=file_path)\n",
    "# html_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e092b7-cf02-4ba2-8f80-822218816386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4b3553-7449-4b2b-9f1d-ac470add5649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e085e22b-3d09-40c4-b50e-d5bd5faa990f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de595393-1538-42fa-a1e0-f5d4b0aa665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export AWS_ACCESS_KEY_ID=\"ASIA3KAKBKFJKIY3RR5Y\"\n",
    "# !export AWS_SECRET_ACCESS_KEY=\"7ukATEPPTA7z5tv227DltV2abaB9mbdw2DrAu4Z3\"\n",
    "# !export AWS_SESSION_TOKEN=\"IQoJb3JpZ2luX2VjEDwaCXVzLWVhc3QtMSJHMEUCIAEczbbS4Nq5XLEG9YiiNegC8l00xzUvdT1M9kirdZcdAiEAtNulJ4daAx8WyScnaZpcTHjcDgpRnHf7I/ORq8PvXsYqmQIIdRAAGgw3Nzc0MTAxMzg0NTAiDFu0Id5Nn1LxlLuEoSr2AYI09mvVmJ54WYyfhhtpE3nB938CWSQVvr2XeTxQ+ENmTOxi5J7UE7aBsWXkjFxlQ8k86h4kRE1p2JpkKNr4uOExkoSbcfZTq6gNKxOazldm8VNWc1elsT812A5+IJUuNt5A0xfAQwGabJ3PSDgCdD3+I5UvPTgx+j6pSn+3yW7Aepce+iOHmpHY9ry3Csg9p0rsV30OfejEXDTtcD0QzP4K8iSozC9FOy04/CDePDranVQBjttkX/n3xdX8nQsbGJ8IhYBtC6SGd1OnRgKO6NVC1T427hvjO4VO6xHH+x+hubG3Tc8upofdPB5fy2E5bHS6oT0kSjCi+J2qBjqdAT8EfLYVAhajXS/Ab7SioPvrwLQP2ig524BakU71xAEmUDEPDI8oz8S6uSfoyscuXpjwlDsL0pUHRTDoXCyKXVEq2k9w8NtVpJcepmz5Td/70ltI9CFt5IBLyHVkDoAxKUVM+vF7JbCG+wXij1uZjpv0wsQuQCUSV7wMbvanoV6I8nVDS0CqNCC4YC9qE6BE5xwD/AIwk3Kah1yBrwk=\"\n",
    "# export AWS_ACCESS_KEY_ID=\"ASIA3KAKBKFJNSH2GEWG\"\n",
    "# export AWS_SECRET_ACCESS_KEY=\"WxFiEe9AzxJeSvqB4OHr+vjsUzsvVgJd3+ekhsQQ\"\n",
    "# export AWS_SESSION_TOKEN=\"IQoJb3JpZ2luX2VjED0aCXVzLWVhc3QtMSJHMEUCIDoAaVM1vKVdp6cVnnm1sqPp3bPLfYi6vIbVXrwk6PPGAiEAoDrVUMt8Jp6MOVeYvRDXh5nHpgJpt7HBgR4vBZCsmQ4qmQIIdhAAGgw3Nzc0MTAxMzg0NTAiDFyKoKe/P7MLcqTGUir2AQDJez8zWtL1Z7FWq0Wpyp8Jug9riE452UBez6hc1G5nCqh2o7ZpyjCmV2lpRfCGOGETsYwwPMpbMr+QsTqcgDBHh5GX5CoJz95HnnHjTEC8aigs8L2xHjQqPr4GhLWEQ31mMfAzISjpCnzvFCx3xir1+CnW8vt6PnUXkDXAWLlxDfgj5SBKAMn+GdrjR/EsNNUE6cFfsZ4V0J/G+abSvi9b/mznHPedbAzSXPIVVcrMaN/L4wzfGUj5ldBfZa2baapVFv6ZnJyX2jJxp0LRq4jjmKCmFBWZ1Va2d6SCaJh70o0lquTRskUk6QpaWPWnN3Ncwt8WsjD/nJ6qBjqdAQtCq8GXqGTgxSBzt7C2ZT0kYWLNZqDEa6XyT6QYH28WUWzlrJlBIxK7qyaAKJ8hVPpbNo1qhcPPmVxXbbwycginl9wnxqLsSL9rrKC8uI7FXFMUgl/SQLaI3GMK0PbKgOXQ6Uw4wxIX5Qg/GkUULBQcWJEOGPP7qvlXlUD7fhjYMjbugupRl0PH6ce9KIGgn1euPqt1HouU1NJ9YTg=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5126c700-d5e2-4fdc-8b6b-0bac4198740f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Config template extra",
   "language": "python3",
   "name": "extra"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
